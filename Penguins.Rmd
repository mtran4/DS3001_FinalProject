---
title: "Penguins"
author: "Maggie Tran"
date: "12/6/2021"
output: 
  rmarkdown::html_document
  theme: hpstr
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#install.packages("prettydoc")
library(tidyverse)
library(caret)
library(randomForest)
library(rio)
library(mltools)
library(data.table)
library(plotly)
```

```{r}
penguins <- read_csv("penguins_lter.csv")

colnames(penguins) <- c("Study_Name","Sample_Number","Species","Region","Island","Stage","ID","Clutch_Completion","Date_Egg","Culmen_Length","Culmen_Depth","Flipper_Length","Body_Mass","Sex","Delta_15_N","Delta_13_C","Comments")
```

```{r}
penguins_clean <- penguins[c(3, 5, 8, 10, 11, 12, 13, 14, 15, 16)]

colnames(penguins_clean) <- c("Species","Island","Clutch_Completion","Culmen_Length","Culmen_Depth","Flipper_Length","Body_Mass","Sex","Delta_15_N","Delta_13_C")

penguins_clean$Species <- recode(penguins_clean$Species, "Adelie Penguin (Pygoscelis adeliae)" = "Adelie", "Chinstrap penguin (Pygoscelis antarctica)" = "Chinstrap", "Gentoo penguin (Pygoscelis papua)" = "Gentoo")

penguins_clean$Clutch_Completion <- recode(penguins_clean$Clutch_Completion, "Yes" = 1, "No" = 0)

penguins_clean$Sex <- recode(penguins_clean$Sex,
                         "FEMALE" = 0,
                         "MALE" = 1)

penguins_clean[penguins_clean == "."] <- NA


penguins_clean[c(1,2,3,8)] <- lapply(penguins_clean[c(1,2,3,8)], function(x) as.factor(x))

str(penguins_clean)
    
``` 

```{r}
penguins_clean %>%
  mutate(Species = Species %>% fct_infreq() %>% fct_rev())%>%
  ggplot(aes(x=Species, fill = Species)) +
  geom_bar()


```

```{r}
penguins_clean %>%
  filter(Species == "Adelie") %>%
  summary()

penguins_clean %>%
  filter(Species == "Chinstrap") %>%
  summary()

penguins_clean %>%
  filter(Species == "Gentoo") %>%
  summary()
```

```{r}
penguins_clean %>%
  group_by(Island) %>%
  ggplot(aes(Species, fill = Species)) + 
  geom_bar() +
  facet_wrap(~ Island, ncol = 3)
```

```{r}
# Take care of missing data
table(is.na(penguins_clean)) # missing 46
penguins_clean <- penguins_clean[complete.cases(penguins_clean), ]
dim(penguins_clean)
table(is.na(penguins_clean))
```

```{r}
# Create test, tune and training sets 
part_index_1 <- caret::createDataPartition(penguins_clean$Sex,
                                           times=1,
                                           p = 0.50,
                                           groups=1,
                                           list=FALSE)

train <- penguins_clean[part_index_1, ]
tune_and_test <- penguins_clean[-part_index_1, ]

#The we need to use the function again to create the tuning set 

tune_and_test_index <- createDataPartition(tune_and_test$Sex,
                                           p = .5,
                                           list = FALSE,
                                           times = 1)

tune <- tune_and_test[tune_and_test_index, ]
test <- tune_and_test[-tune_and_test_index, ]


dim(train)
dim(test)
dim(tune)
```


## Calculating the Initial mtry level 
```{r}
# Calculate the initial mtry level 
mytry_tune <- function(x){
  xx <- dim(x)[2]-1
  sqrt(xx)
}
       
mytry_tune(penguins_clean)
```
## Running the Random Forest model
```{r}
# Run the initial RF model
set.seed(2023)
penguins_RF = randomForest(Sex~.,          #<- Formula: response variable ~ predictors.
                            #   The period means 'use all other variables in the data'.
                            train,     #<- A data frame with the variables to be used.
                            #y = NULL,           #<- A response vector. This is unnecessary because we're specifying a response formula.
                            #subset = NULL,      #<- This is unnecessary because we're using all the rows in the training data set.
                            #xtest = NULL,       #<- This is already defined in the formula by the ".".
                            #ytest = NULL,       #<- This is already defined in the formula by "PREGNANT".
                            ntree = 500,        #<- Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets classified at least a few times.
                            mtry = 3,            #<- Number of variables randomly sampled as candidates at each split. Default number for classification is sqrt(# of variables). Default number for regression is (# of variables / 3).
                            replace = TRUE,      #<- Should sampled data points be replaced.
                            #classwt = NULL,     #<- Priors of the classes. Use this if you want to specify what proportion of the data SHOULD be in each class. This is relevant if your sample data is not completely representative of the actual population 
                            #strata = NULL,      #<- Not necessary for our purpose here.
                            sampsize = 50,      #<- Size of sample to draw each time.
                            nodesize = 5,        #<- Minimum numbers of data points in terminal nodes.
                            #maxnodes = NULL,    #<- Limits the number of maximum splits. 
                            importance = TRUE,   #<- Should importance of predictors be assessed?
                            #localImp = FALSE,   #<- Should casewise importance measure be computed? (Setting this to TRUE will override importance.)
                            proximity = TRUE,    #<- Should a proximity measure between rows be calculated?
                            norm.votes = TRUE,   #<- If TRUE (default), the final result of votes are expressed as fractions. If FALSE, raw vote counts are returned (useful for combining results from different runs).
                            do.trace = TRUE,     #<- If set to TRUE, give a more verbose output as randomForest is run.
                            keep.forest = TRUE,  #<- If set to FALSE, the forest will not be retained in the output object. If xtest is given, defaults to FALSE.
                            keep.inbag = TRUE)   #<- Should an n by ntree matrix be returned that keeps track of which samples are in-bag in which trees?
```

## Output of the Random Forest 
```{r}
# Look at the output of the random forest
penguins_RF

# This is how you can call up the criteria we set for the random forest:
penguins_RF$call

# Call up the confusion matrix and check the accuracy of the model.
penguins_RF$confusion
penguins_RF_acc = sum(penguins_RF$confusion[row(penguins_RF$confusion) == 
                                                col(penguins_RF$confusion)]) / 
  sum(penguins_RF$confusion)

penguins_RF_acc
# 0.89ish
```


## Evaluation Metrics 
```{r}
#View the percentage of trees that voted for each data point to be in each class 
View(as.data.frame(penguins_RF$votes))

# View the "predicted" argument that contains a vector of predictions for each data point 
View(as.data.frame(penguins_RF$predicted))

# View the importance of each variable 
View(as.data.frame(importance(penguins_RF, type=2, scale=TRUE)))

# The most important variable in determining the penguin's gender is the Species of the penguin based on a Mean Decrease Gini value of 0.997

# Using the proximity to find the average number of trees for which the data points occupy the same terminal node 
str(as.data.frame(penguins_RF$proximity))
View(as.data.frame(penguins_RF$proximity))

```


## Visualizing the Random Forest Results
```{r}
penguins_RF_error = data.frame(1:nrow(penguins_RF$err.rate), penguins_RF$err.rate)
colnames(penguins_RF_error) = c("Number of Trees", "Out of Bag", "Female", "Male")

penguins_RF_error$Diff <- penguins_RF_error$Male-penguins_RF_error$Female

rm(fig)
fig <- plot_ly(x=penguins_RF_error$`Number of Trees`, y=penguins_RF_error$Diff,name="Diff", type = 'scatter', mode = 'lines')
fig <- fig %>% add_trace(y=penguins_RF_error$`Out of Bag`, name="OOB_Er")
fig <- fig %>% add_trace(y=penguins_RF_error$Female, name="Female")
fig <- fig %>% add_trace(y=penguins_RF_error$Male, name="Male")

fig

```


## Optimizing the Random Forest Model 
```{r}
set.seed(2022)
penguins_RF_2 = randomForest(Sex~.,          #<- Formula: response variable ~ predictors.
                            #   The period means 'use all other variables in the data'.
                            train,     #<- A data frame with the variables to be used.
                            #y = NULL,           #<- A response vector. This is unnecessary because we're specifying a response formula.
                            #subset = NULL,      #<- This is unnecessary because we're using all the rows in the training data set.
                            #xtest = NULL,       #<- This is already defined in the formula by the ".".
                            #ytest = NULL,       #<- This is already defined in the formula by "PREGNANT".
                            ntree = 600,        #<- Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets classified at least a few times.
                            mtry = 3,            #<- Number of variables randomly sampled as candidates at each split. Default number for classification is sqrt(# of variables). Default number for regression is (# of variables / 3).
                            replace = TRUE,      #<- Should sampled data points be replaced.
                            #classwt = NULL,     #<- Priors of the classes. Use this if you want to specify what proportion of the data SHOULD be in each class. This is relevant if your sample data is not completely representative of the actual population 
                            #strata = NULL,      #<- Not necessary for our purpose here.
                            sampsize = 25,      #<- Size of sample to draw each time.
                            nodesize = 5,        #<- Minimum numbers of data points in terminal nodes.
                            #maxnodes = NULL,    #<- Limits the number of maximum splits. 
                            importance = TRUE,   #<- Should importance of predictors be assessed?
                            #localImp = FALSE,   #<- Should casewise importance measure be computed? (Setting this to TRUE will override importance.)
                            proximity = TRUE,    #<- Should a proximity measure between rows be calculated?
                            norm.votes = TRUE,   #<- If TRUE (default), the final result of votes are expressed as fractions. If FALSE, raw vote counts are returned (useful for combining results from different runs).
                            do.trace = TRUE,     #<- If set to TRUE, give a more verbose output as randomForest is run.
                            keep.forest = TRUE,  #<- If set to FALSE, the forest will not be retained in the output object. If xtest is given, defaults to FALSE.
                            keep.inbag = TRUE)   #<- Should an n by ntree matrix be returned that keeps track of which samples are in-bag in which trees?
``` 

## Comparison between the Random Forest Models 
```{r}
penguins_RF$confusion 
#   0  1 class.error
#0 73  9  0.10975610
#1  7 74  0.08641975

# False Positive Rate 
9/(9+74) # 0.108 

# Specificity
1 - 9/(9+74) # 0.892

# True Positive Rate 
73/(73+7) # 0.913

penguins_RF_2$confusion
#   0  1 class.error
#0 72 10  0.12195122
#1 11 70   0.1358025

``` 

Based on the results from the confusion matrix, the first model has a lower classification error rate than the second model. The first model is better at classifying both 


```{r}
penguins_predict = predict(penguins_RF_2,      #<- a randomForest model
                            test,      #<- the test data set to use
                            type = "response",   #<- what results to produce, see the help menu for the options
                            predict.all = FALSE,  #<- should the predictions of all trees be kept?
                            proximity = FALSE)    #<- should proximity measures be computed

View(penguins_predict)

```



```{r}
hist(treesize(penguins_RF_2, terminal=FALSE))

```

## Final Results 

## Conclusion 

## Future Work 





