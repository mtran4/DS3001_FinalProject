---
title: "Penguins"
author: "Maggie Tran"
date: "12/6/2021"
output: 
  rmarkdown::html_document
  theme: hpstr
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
#install.packages("prettydoc")
library(tidyverse)
library(caret)
library(randomForest)
library(rio)
library(mltools)
library(data.table)
library(plotly)
```

```{r}
penguins <- read_csv("penguins_lter.csv")

colnames(penguins) <- c("Study_Name","Sample_Number","Species","Region","Island","Stage","ID","Clutch_Completion","Date_Egg","Culmen_Length","Culmen_Depth","Flipper_Length","Body_Mass","Sex","Delta_15_N","Delta_13_C","Comments")
```

```{r}
penguins_clean <- penguins[c(3, 5, 8, 10, 11, 12, 13, 14, 15, 16)]

colnames(penguins_clean) <- c("Species","Island","Clutch_Completion","Culmen_Length","Culmen_Depth","Flipper_Length","Body_Mass","Sex","Delta_15_N","Delta_13_C")

penguins_clean$Species <- recode(penguins_clean$Species, "Adelie Penguin (Pygoscelis adeliae)" = "Adelie", "Chinstrap penguin (Pygoscelis antarctica)" = "Chinstrap", "Gentoo penguin (Pygoscelis papua)" = "Gentoo")

penguins_clean$Clutch_Completion <- recode(penguins_clean$Clutch_Completion, "Yes" = 1, "No" = 0)

penguins_clean$Sex <- recode(penguins_clean$Sex,
                         "FEMALE" = 0,
                         "MALE" = 1)

penguins_clean[penguins_clean == "."] <- NA


penguins_clean[c(1,2,3,8)] <- lapply(penguins_clean[c(1,2,3,8)], function(x) as.factor(x))

str(penguins_clean)
    
``` 

```{r}
penguins_clean %>%
  mutate(Species = Species %>% fct_infreq() %>% fct_rev())%>%
  ggplot(aes(x=Species, fill = Species)) +
  geom_bar()


```

```{r}
penguins_clean %>%
  filter(Species == "Adelie") %>%
  summary()

penguins_clean %>%
  filter(Species == "Chinstrap") %>%
  summary()

penguins_clean %>%
  filter(Species == "Gentoo") %>%
  summary()
```

```{r}
penguins_clean %>%
  group_by(Island) %>%
  ggplot(aes(Species, fill = Species)) + 
  geom_bar() +
  facet_wrap(~ Island, ncol = 3)
```

```{r}
# Take care of missing data
table(is.na(penguins_clean)) # missing 46
penguins_clean <- penguins_clean[complete.cases(penguins_clean), ]
dim(penguins_clean)
table(is.na(penguins_clean))
```

```{r}
# Create test, tune and training sets 
part_index_1 <- caret::createDataPartition(penguins_clean$Sex,
                                           times=1,
                                           p = 0.75,
                                           groups=1,
                                           list=FALSE)

train <- penguins_clean[part_index_1, ]
test <- penguins_clean[-part_index_1, ]

#The we need to use the function again to create the tuning set 

dim(train)
dim(test)
```


## Calculating the Initial mtry level 
```{r}
# Calculate the initial mtry level 
mytry_tune <- function(x){
  xx <- dim(x)[2]-1
  sqrt(xx)
}
       
mytry_tune(penguins_clean)
```
## Running the Random Forest model
```{r}
# Run the initial RF model
set.seed(2023)
penguins_RF = randomForest(Sex~.,          #<- Formula: response variable ~ predictors.
                            #   The period means 'use all other variables in the data'.
                            train,     #<- A data frame with the variables to be used.
                            #y = NULL,           #<- A response vector. This is unnecessary because we're specifying a response formula.
                            #subset = NULL,      #<- This is unnecessary because we're using all the rows in the training data set.
                            #xtest = NULL,       #<- This is already defined in the formula by the ".".
                            #ytest = NULL,       #<- This is already defined in the formula by "PREGNANT".
                            ntree = 500,        #<- Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets classified at least a few times.
                            mtry = 3,            #<- Number of variables randomly sampled as candidates at each split. Default number for classification is sqrt(# of variables). Default number for regression is (# of variables / 3).
                            replace = TRUE,      #<- Should sampled data points be replaced.
                            #classwt = NULL,     #<- Priors of the classes. Use this if you want to specify what proportion of the data SHOULD be in each class. This is relevant if your sample data is not completely representative of the actual population 
                            #strata = NULL,      #<- Not necessary for our purpose here.
                            sampsize = 50,      #<- Size of sample to draw each time.
                            nodesize = 5,        #<- Minimum numbers of data points in terminal nodes.
                            #maxnodes = NULL,    #<- Limits the number of maximum splits. 
                            importance = TRUE,   #<- Should importance of predictors be assessed?
                            #localImp = FALSE,   #<- Should casewise importance measure be computed? (Setting this to TRUE will override importance.)
                            proximity = TRUE,    #<- Should a proximity measure between rows be calculated?
                            norm.votes = TRUE,   #<- If TRUE (default), the final result of votes are expressed as fractions. If FALSE, raw vote counts are returned (useful for combining results from different runs).
                            do.trace = TRUE,     #<- If set to TRUE, give a more verbose output as randomForest is run.
                            keep.forest = TRUE,  #<- If set to FALSE, the forest will not be retained in the output object. If xtest is given, defaults to FALSE.
                            keep.inbag = TRUE)   #<- Should an n by ntree matrix be returned that keeps track of which samples are in-bag in which trees?
```

## Output of the Random Forest 
```{r}
# Look at the output of the random forest
penguins_RF

# This is how you can call up the criteria we set for the random forest:
penguins_RF$call

# Call up the confusion matrix and check the accuracy of the model.
penguins_RF$confusion
penguins_RF_acc = sum(penguins_RF$confusion[row(penguins_RF$confusion) == 
                                                col(penguins_RF$confusion)]) / 
  sum(penguins_RF$confusion)

penguins_RF_acc
# 0.89ish
```


## Evaluation Metrics 
```{r}
#View the percentage of trees that voted for each data point to be in each class 
View(as.data.frame(penguins_RF$votes))

# View the "predicted" argument that contains a vector of predictions for each data point 
View(as.data.frame(penguins_RF$predicted))

# View the importance of each variable 
View(as.data.frame(importance(penguins_RF, type=2, scale=TRUE)))

# The most important variable in determining the penguin's gender is the Species of the penguin based on a Mean Decrease Gini value of 0.997

# Using the proximity to find the average number of trees for which the data points occupy the same terminal node 
str(as.data.frame(penguins_RF$proximity))
View(as.data.frame(penguins_RF$proximity))

```


## Visualizing the Random Forest Results
```{r}
penguins_RF_error = data.frame(1:nrow(penguins_RF$err.rate), penguins_RF$err.rate)
colnames(penguins_RF_error) = c("Number of Trees", "Out of Bag", "Female", "Male")

penguins_RF_error$Diff <- penguins_RF_error$Male-penguins_RF_error$Female

rm(fig)
fig <- plot_ly(x=penguins_RF_error$`Number of Trees`, y=penguins_RF_error$Diff,name="Diff", type = 'scatter', mode = 'lines')
fig <- fig %>% add_trace(y=penguins_RF_error$`Out of Bag`, name="OOB_Er")
fig <- fig %>% add_trace(y=penguins_RF_error$Female, name="Female")
fig <- fig %>% add_trace(y=penguins_RF_error$Male, name="Male")

fig

```

From the plot, we see that the error starts to even out at 100 trees so we'll change the model to 100 trees. 


## Optimizing the Random Forest Model 
```{r}
set.seed(2022)
penguins_RF_2 = randomForest(Sex~.,          #<- Formula: response variable ~ predictors.
                            #   The period means 'use all other variables in the data'.
                            train,     #<- A data frame with the variables to be used.
                            #y = NULL,           #<- A response vector. This is unnecessary because we're specifying a response formula.
                            #subset = NULL,      #<- This is unnecessary because we're using all the rows in the training data set.
                            #xtest = NULL,       #<- This is already defined in the formula by the ".".
                            #ytest = NULL,       #<- This is already defined in the formula by "PREGNANT".
                            ntree = 200,        #<- Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets classified at least a few times.
                            mtry = 3,            #<- Number of variables randomly sampled as candidates at each split. Default number for classification is sqrt(# of variables). Default number for regression is (# of variables / 3).
                            replace = TRUE,      #<- Should sampled data points be replaced.
                            #classwt = NULL,     #<- Priors of the classes. Use this if you want to specify what proportion of the data SHOULD be in each class. This is relevant if your sample data is not completely representative of the actual population 
                            #strata = NULL,      #<- Not necessary for our purpose here.
                            sampsize = 30,      #<- Size of sample to draw each time.
                            nodesize = 3,        #<- Minimum numbers of data points in terminal nodes.
                            #maxnodes = NULL,    #<- Limits the number of maximum splits. 
                            importance = TRUE,   #<- Should importance of predictors be assessed?
                            #localImp = FALSE,   #<- Should casewise importance measure be computed? (Setting this to TRUE will override importance.)
                            proximity = TRUE,    #<- Should a proximity measure between rows be calculated?
                            norm.votes = TRUE,   #<- If TRUE (default), the final result of votes are expressed as fractions. If FALSE, raw vote counts are returned (useful for combining results from different runs).
                            do.trace = TRUE,     #<- If set to TRUE, give a more verbose output as randomForest is run.
                            keep.forest = TRUE,  #<- If set to FALSE, the forest will not be retained in the output object. If xtest is given, defaults to FALSE.
                            keep.inbag = TRUE)   #<- Should an n by ntree matrix be returned that keeps track of which samples are in-bag in which trees?
``` 

## Comparison between the Random Forest Models 
```{r}
penguins_RF$confusion 
penguins_RF_2$confusion
#   0  1 class.error
#0 73  9  0.10975610
#1  7 74  0.08641975

# False Positive Rate 
9/(9+74) # 0.108 

# Specificity
1 - 9/(9+74) # 0.892

# True Positive Rate 
73/(73+7) # 0.913

penguins_RF_2$confusion
#   0  1 class.error
#0 72 10  0.12195122
#1 11 70   0.1358025

varImpPlot(penguins_RF_2, main = "Important Factors for Identifying the Sex of Penguins", color = "blue", lcolor = "orange")
``` 



## Predictions with the Training Data Set 
```{r}
penguins_predict = predict(penguins_RF_2,      #<- a randomForest model
                            train,      #<- the train data set to use
                            type = "response",   #<- what results to produce, see the help menu for the options
                            predict.all = TRUE,  #<- should the predictions of all trees be kept?
                            proximity = FALSE)    #<- should proximity measures be computed

penguins_train_pred = data.frame(train,Prediction = penguins_predict$aggregate)
View(penguins_train_pred)

# Create a confusion matrix 
confusionMatrix(penguins_train_pred$Prediction, penguins_train_pred$Sex, positive="1",dnn=c("Prediction", "Actual"), mode="everything")


```
* write about evaluation metrics here and which ones mean the most 
* sensitivity, and specificity
* less gentoo -- but not a significant imbalance
* accuracy -- data is balanced 
* talk about prevalence -- The data shows a baserate of 49.6% male penguins. 

## Predictions with the Test Data Set 
```{r}
penguins_predict_test = predict(penguins_RF_2,      #<- a randomForest model
                            test,      #<- the test data set to use
                            type = "response",   #<- what results to produce, see the help menu for the options
                            predict.all = TRUE,  #<- should the predictions of all trees be kept?
                            proximity = FALSE)    #<- should proximity measures be computed

View(penguins_predict_test)
View(penguins_predict_test$aggregate)
View(penguins_predict_test$individual)

penguins_test_pred = data.frame(test,Prediction = penguins_predict_test$aggregate)
View(penguins_test_pred)

# Create a confusion matrix 
confusionMatrix(penguins_test_pred$Prediction, penguins_test_pred$Sex, positive="1",
                dnn=c("Prediction", "Actual"), mode="everything")

```
- talk about evaluation metrics for testing data here 

### ROC Curve 
```{r}
penguins_RF_2_prediction = as.data.frame(as.numeric(as.character(penguins_RF_2$votes[,2])))
View(penguins_RF_2_prediction)

# Let's also take the actual classification of each data point and convert
# it to a data frame with numbers. R classifies a point in either bucket 
# at a 50% threshold.
penguins_train_actual = data.frame(train[,8])

View(penguins_train_actual)

penguins_prediction_comparison = prediction(penguins_RF_2_prediction,           
                                             penguins_train_actual)#<- a list or data frame with actual class assignments
View(penguins_prediction_comparison)

penguins_pred_performance = performance(penguins_prediction_comparison, 
                                         measure = "tpr",    #<- performance measure to use for the evaluation
                                         x.measure = "fpr")  #<- 2nd performance measure to use for the evaluation
View(penguins_pred_performance)

penguins_rates = data.frame(fp = penguins_prediction_comparison@fp,  #<- false positive classification.
                             tp = penguins_prediction_comparison@tp,  #<- true positive classification.
                             tn = penguins_prediction_comparison@tn,  #<- true negative classification.
                             fn = penguins_prediction_comparison@fn)  #<- false negative classification.

colnames(penguins_rates) = c("fp", "tp", "tn", "fn")

View(penguins_rates)

# Now let's calculate the true positive and false positive rates for the classification.
str(penguins_rates)
tpr = penguins_rates$tp / (penguins_rates$tp + penguins_rates$fn)
fpr = penguins_rates$fp / (penguins_rates$fp + penguins_rates$tn)

# Compare the values with the output of the performance() function, they are the same.
penguins_rates_comparison = data.frame(penguins_pred_performance@x.values,
                                        penguins_pred_performance@y.values,
                                        fpr,
                                        tpr)
colnames(penguins_rates_comparison) = c("x.values","y.values","fpr","tpr") #<- rename columns accordingly.
View(penguins_rates_comparison)

# Now plot the results.
plot(fpr,          #<- x-axis value.
     tpr,          #<- y-axis value.
     col = "blue",  #<- color of the line. 
     type = "l")
grid(col = "black")
# The performance() function saves us a lot of time, and can be used directly
# to plot the ROC curve.
plot(penguins_pred_performance, 
     col = "red", 
     lwd = 3, 
     main = "ROC curve")
grid(col = "black")


# Add a 45 degree line.
abline(a = 0, 
       b = 1,
       lwd = 2,
       lty = 2,
       col = "gray")

```


## Final Results 

## Conclusion 

## Future Work 





